# from icrawler.builtin import BaiduImageCrawler
from icrawler.builtin import BingImageCrawler
#需要爬取的关键字i
list_word = ['IU']
for word in list_word:
    #bing爬虫
    #保存路径
    bing_storage = {'root_dir':'photo\\'+word}#photo为主文件名，可以修改为别的名称，，列表有多少个，我们就在主列表产生
    #从上到下依次是解析器线程数，下载线程数，还有上面设置的保存路径
    bing_crawler = BingImageCrawler(parser_threads=4,
                                    downloader_threads=8,
                                    storage=bing_storage)
    #开始爬虫，关键字+图片数量
    bing_crawler.crawl(keyword=word,
                       max_num=50)

    #百度爬虫
    # baidu_storage = {'root_dir': 'baidu\\' + word}
    # baidu_crawler = BaiduImageCrawler(parser_threads=2,
    #                                   downloader_threads=4,
    #                                   storage=baidu_storage)
    # baidu_crawler.crawl(keyword=word,
    #                     max_num=2000)


    # google爬虫
    # google_storage = {'root_dir': '‘google\\' + word}
    # google_crawler = GoogleImageCrawler(parser_threads=4,
    #                                    downloader_threads=4,
    #                                    storage=google_storage)
    # google_crawler.crawl(keyword=word,
    #                      max_num=2000)

